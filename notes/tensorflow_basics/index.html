<!DOCTYPE html>
<head>
<title>Tensorflow Basics - Daniel Urencio</title>
<meta charset="UTF-8">
<link rel="stylesheet" type="text/css" href="../../style.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dark.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://d3js.org/d3.v3.min.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script>hljs.initHighlightingOnLoad();</script>
<script src='../../plotGraphs.js'></script>
</head>

<body style='color:rgb(50,50,50);'>
 <div id="t">
&ensp;Tensorflow Basics
 </div>

 <div id="p">
  Why Tensorflow? It is Google's own machine learning library and a very popular one. Tensorflow is useful either for building simple and intuitive models or for deploying massive applications that can be distributed among many different devices, like dedicated servers or even mobile devices.
<br><br>
As the title of these notes suggest, the main concepts and utilities of this library are going to be explored.
 </div>

 <div id="st">
&ensp;It is all about computational graphs
 </div>

 <div id="p">
 The hay Tensorflow works is based on computing things through graphs. What does this mean exactly? A graph, perhaps, might be the best way to make this idea clear.
 </div>

 <div id="i_0">
 </div>

 <div id="p">
A graph, in the mathematical sense, is a set of elements that may or may not keep some sort of relationship. It is like a network where the elements are represented by nodes and the relationship between them are represented by vertices. In Tensorflow, nodes are mathematical operations and vertices signal the direction the data flows towards.
<br><br>
In the example from above information flows from left to right. The outer left nodes represent placeholders for data that will undergo certain mathematical operations; nodes <b>A</b>, <b>B</b> and <b>C</b> hold a constant value of <b>3</b>, <b>2</b> and <b>1</b> respectively. Node <b>D</b> performs a sum operation and depends on the values of <b>A</b> and <b>B</b> to compute a quantity of <b>5</b> (<b>D = A + B</b>). Similarly, <b>E</b> has dependence on <b>B</b> and <b>C</b> to compute a value of <b>1</b> through substraction (<b>E = B - C</b>).
<br><br>
Finally, as this graph's ultimate goal, node <b>F</b> computes a value of <b>1</b> (<b>F = D * E</b>) through a multiplication operation that has direct dependency on nodes <b>D</b> and <b>E</b>. However, this last node indirectly depends on the values or operations that exist before its immediate neighbour nodes (<b>A</b>, <b>B</b> and <b>C</b>).
 </div>

 <div id="st">
&ensp;But, why computational graphs?
 </div>

 <div id="p">
Computational graphs behave like an assembly process. Given that dependencies among nodes can be tracked, the computation process can be decomposed into several subprocesses for which computational resources can be allocated according to different needs. This is what allows a graph-based computation system to be distributed among different machines.
<br><br>
Furthermore, graphs are extremely flexible when it comes to building quantitative models as simple as linear regression or as sophisticated as some neural networks architechtures. So, the reason why computational graphs are interesing, not to mention useful, is that both scalability and flexibility can build any kind of application no matter how simple or complex; hence, Tensorflow is worth exploring in depth.
 </div>

 <div id='st'>
&ensp;A bit of code to exemplify
 </div>

 <div id='p' style='margin-bottom:10px;'>
There is a Tensorflow API in Python which is great for data science projects. The code for computing the graph plotted above is as simple as what follows.
 </div>

 <pre>
  <code class="python">
   import tensorflow as tf

   #  == First layer ==
   A = tf.constant(3)
   B = tf.constant(2)
   C = tf.constant(1)

   #  == Second layer ==
   D = tf.add(A,B)             #   Same as A + B semantically,
   E = tf.subtract(B,C)        #    ...    B - C ...

   #  == Target node ==
   F = tf.multiply(D,E)        #    ...    D * E ...

   #  == Intitialize session, execute it and close it ==
   sess = tf.Session()
   output = sess.run(F)
   sess.close()
  </code>
 </pre>

 <div id='p'>
Apart from the last three lines from the previous block, the entire code is self-explanatory. Once the graph has been constructed a <i><b>session</b></i>, through the <span style='font-family:monospace;'>tf.Session()</span> command, is required. Sessions are the contexts where the computation and calculations are preformed; in the above example, the output, obtained with node <b>F</b>, is stored inside the variable named <span style='font-family:"monospace";'>output</span>. After the computation is done, the session should be closed to free computational resources.
 </div>

 <div id='st'>
&ensp;Graphs, sessions and the <span style='font-family:monospace;'>with</span> command
 </div>

 <div id='p' style='margin-bottom:10px;'>
 <span style='font-weight:700'>Graphs</span>
 <br>
By default Tensorflow creates a graph. This default graph is the one that is used when declaring nodes and computing its values; however, other graphs can be explicitly declared.
 </div>
 
 <pre>
  <code class="python">
   new_graph = tf.Graph()
  </code>
 </pre>

 <div id='p' style='margin-bottom:10px;'>
 <span style='font-weight:700;'>Interactive session</span>
  <br>
  Besides the conventional sessions, Tensorflows has a very useful command for evaluating the content of variables and placeholders (which will be discussed shortly).
 </div>

 <pre>
  <code class="python">
   sess_ = tf.InteractiveSession()

   x = tf.constant([[1,2],
		    [3,4]])

   x.eval() 	# <-- Evaluates and prints what is stored in 'x'.

   sess_.close()
  </code>
 </pre>

 <div id='p'>
Interactive sessions are useful when experimenting or inspecting what kind of data types and shapes are to be feed to a graph.
 </div>
<script src='script.js'></script>
</body>
</html>
